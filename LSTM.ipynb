{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdcb82-eb71-4b4d-a48c-23157a0c47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # https://docs.python.org/3/library/os.html\n",
    "import pandas as pd # https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "import numpy as np # https://numpy.org/doc/2.2/\n",
    "import matplotlib.pyplot as plt # https://matplotlib.org/stable/index.html\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from keras.models import Sequential # https://keras.io/guides/sequential_model/\n",
    "from keras.layers import LSTM, Dropout, Dense # https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "from sklearn.model_selection import TimeSeriesSplit # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "from keras.optimizers import Adam # https://keras.io/api/optimizers/\n",
    "from keras.callbacks import EarlyStopping # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "\n",
    "# Folder paths for training and test datasets\n",
    "train_folder = \" \" # Path to a train set\n",
    "test_folder = \" \" # Path to a test set\n",
    "\n",
    "# Function to load and concatenate all CSV files in a folder into a single DataFrame\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "def load_multiple_csv(folder_path):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    # Read each CSV and concatenate them into a single DataFrame\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, csv_file)) for csv_file in csv_files]\n",
    "    # Concatenate all DataFrames and reset index\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = load_multiple_csv(train_folder)\n",
    "test_df = load_multiple_csv(test_folder)\n",
    "\n",
    "# Ensure data was loaded properly\n",
    "if train_df is None or test_df is None:\n",
    "    raise ValueError(\"Error: Could not load training or testing data.\")\n",
    "\n",
    "# Convert Date column to DateTime format and set it as index\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "train_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"])\n",
    "train_df.set_index(\"Date\", inplace=True) # Set Date column as index https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html\n",
    "test_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"])\n",
    "test_df.set_index(\"Date\", inplace=True) # Set Date column as index\n",
    "\n",
    "# Encode the 'Symbol' column to numerical values\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "encoder = LabelEncoder()\n",
    "train_df[\"Symbol_Encoded\"] = encoder.fit_transform(train_df[\"Symbol\"])\n",
    "test_df[\"Symbol_Encoded\"] = encoder.transform(test_df[\"Symbol\"])\n",
    "\n",
    "# Save mappings for future reference or output\n",
    "symbol_mapping = dict(zip(train_df[\"Symbol_Encoded\"], train_df[\"Symbol\"]))\n",
    "name_mapping = dict(zip(train_df[\"Symbol_Encoded\"], train_df[\"Name\"]))\n",
    "\n",
    "# Remove original Symbol and Name columns\n",
    "train_df = train_df.drop(columns=[\"Symbol\", \"Name\"])\n",
    "test_df = test_df.drop(columns=[\"Symbol\", \"Name\"])\n",
    "\n",
    "# Initialize containers for forecasts and evaluation metrics\n",
    "all_forecasts = []\n",
    "validation_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "# Explicit list of features to use:\n",
    "features = ['Close','High','Low','Open','Marketcap','Volume','trend','MA_7d','MA_14d', 'MA_30d']\n",
    "\n",
    "# Set up time series cross-validator\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Loop over each crypto asset (by encoded symbol)\n",
    "for symbol_encoded in train_df[\"Symbol_Encoded\"].unique(): # https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html\n",
    "    train_crypto_data = train_df[train_df[\"Symbol_Encoded\"] == symbol_encoded].copy() # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html\n",
    "    test_crypto_data = test_df[test_df[\"Symbol_Encoded\"] == symbol_encoded].copy()\n",
    "\n",
    "    train_crypto_data = train_crypto_data.sort_index() # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html\n",
    "    test_crypto_data = test_crypto_data.sort_index()\n",
    "\n",
    "    print(f\"\\n Running LSTM Forecast for {symbol_mapping[symbol_encoded]} ({name_mapping[symbol_encoded]})\")\n",
    "\n",
    "    # Scale each feature individually using MinMaxScaler\n",
    "    # https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "    scaler_dict = {col: MinMaxScaler() for col in features}\n",
    "    scaled_train_data = np.zeros_like(train_crypto_data[features].values)\n",
    "\n",
    "    for idx, col in enumerate(features):\n",
    "        scaled_train_data[:, idx] = scaler_dict[col].fit_transform(train_crypto_data[[col]]).flatten() # https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.Series.reshape.html\n",
    "\n",
    "    time_step = 30\n",
    "    X, y = [], []\n",
    "    for i in range(time_step, len(scaled_train_data)):\n",
    "        X.append(scaled_train_data[i - time_step:i])\n",
    "        y.append(scaled_train_data[i, features.index(\"Close\")])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "     # Time series cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Define LSTM model\n",
    "        model = Sequential([\n",
    "            LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            Dropout(0.3),\n",
    "            LSTM(50),\n",
    "            Dropout(0.3),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "        forecast_lstm_scaled = model.predict(X_val)\n",
    "\n",
    "        temp_scaled = np.zeros((len(forecast_lstm_scaled), len(features)))\n",
    "        temp_scaled[:, features.index(\"Close\")] = forecast_lstm_scaled.flatten()\n",
    "\n",
    "        for idx, col in enumerate(features):\n",
    "            if col != \"Close\":\n",
    "                temp_scaled[:, idx] = scaled_train_data[val_idx, idx]\n",
    "\n",
    "        forecast_lstm = scaler_dict[\"Close\"].inverse_transform(temp_scaled[:, [features.index(\"Close\")]]).flatten()\n",
    "        actual_values = train_crypto_data[\"Close\"].iloc[val_idx].values\n",
    "\n",
    "        # Validation metrics\n",
    "        val_mae = mean_absolute_error(actual_values, forecast_lstm) # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html\n",
    "        val_mse = mean_squared_error(actual_values, forecast_lstm) # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "        val_rmse = np.sqrt(val_mse) # https://numpy.org/doc/2.1/reference/generated/numpy.sqrt.html\n",
    "        val_mape = mean_absolute_percentage_error(actual_values, forecast_lstm) * 100 # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html\n",
    "\n",
    "        validation_metrics.append([symbol_mapping[symbol_encoded], fold+1, val_mae, val_mse, val_rmse, val_mape])\n",
    "\n",
    "        # Plot predictions\n",
    "        # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "        # https://matplotlib.org/stable/tutorials/index.html\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_crypto_data.index[val_idx], actual_values, label=\"Actual\", marker='o')\n",
    "        plt.plot(train_crypto_data.index[val_idx], forecast_lstm, label=\"Predicted\", marker='o')\n",
    "        plt.title(f\"LSTM Forecast for {symbol_mapping[symbol_encoded]} (Fold {fold+1})\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Initialize an array of zeros with the same shape as the test data for selected features\n",
    "    scaled_test_data = np.zeros_like(test_crypto_data[features].values)\n",
    "    # Apply feature-wise scaling using pre-fitted scalers\n",
    "    for idx, col in enumerate(features):\n",
    "        # Scale each column individually and flatten the result to fit into the array\n",
    "        scaled_test_data[:, idx] = scaler_dict[col].transform(test_crypto_data[[col]]).flatten()\n",
    "\n",
    "    # Prepare sequences for LSTM input\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(time_step, len(scaled_test_data)):\n",
    "        # Append sequences of length 'time_step' to X_test\n",
    "        X_test.append(scaled_test_data[i - time_step:i])\n",
    "        # Append the target variable ('Close' price) at time i to y_test\n",
    "        y_test.append(scaled_test_data[i, features.index(\"Close\")])\n",
    "\n",
    "    # Convert lists to NumPy arrays for model input\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    # Predict the next 7 'Close' values using the trained LSTM model\n",
    "    forecast_lstm_scaled = model.predict(X_test[:7])\n",
    "    # Create a temporary scaled array to help inverse transform predictions\n",
    "    temp_scaled = np.zeros((7, len(features)))\n",
    "    # Fill in only the predicted 'Close' values\n",
    "    temp_scaled[:, features.index(\"Close\")] = forecast_lstm_scaled.flatten()\n",
    "\n",
    "    # For all other features (non-'Close'), copy the original scaled values from test data\n",
    "    for idx, col in enumerate(features):\n",
    "        if col != \"Close\":\n",
    "            temp_scaled[:, idx] = scaled_test_data[:7, idx]\n",
    "\n",
    "    # Inverse transform the predicted 'Close' values back to the original scale\n",
    "    forecast_lstm = scaler_dict[\"Close\"].inverse_transform(temp_scaled[:, [features.index(\"Close\")]]).flatten()\n",
    "    # Extract the actual 'Close' values from the test data for comparison\n",
    "    actual_values = test_crypto_data[\"Close\"].values[:7]\n",
    "\n",
    "    # Calculate test metrics\n",
    "    test_mae = mean_absolute_error(actual_values, forecast_lstm)\n",
    "    test_mse = mean_squared_error(actual_values, forecast_lstm)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = mean_absolute_percentage_error(actual_values, forecast_lstm) * 100\n",
    "\n",
    "    # Append the metrics to a results list, tagged with the corresponding crypto symbol\n",
    "    test_metrics.append([symbol_mapping[symbol_encoded], test_mae, test_mse, test_rmse, test_mape])\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(test_crypto_data.index[:7], actual_values, label=\"Actual\", marker='o')\n",
    "    plt.plot(test_crypto_data.index[:7], forecast_lstm, label=\"Predicted\", marker='o')\n",
    "    plt.title(f\"LSTM Test Forecast for {symbol_mapping[symbol_encoded]}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Build final forecast table for this crypto\n",
    "    forecast_table = pd.DataFrame({\n",
    "        \"Date\": test_crypto_data.index[:7],\n",
    "        \"Symbol\": symbol_mapping[symbol_encoded],\n",
    "        \"Actual Value\": actual_values,\n",
    "        \"Predicted Value\": forecast_lstm\n",
    "    })\n",
    "    print(forecast_table)\n",
    "    all_forecasts.append(forecast_table)\n",
    "\n",
    "# Combine forecasts for all cryptocurrencies\n",
    "final_forecast_df = pd.concat(all_forecasts, ignore_index=True)\n",
    "print(\"\\n Final Forecasted vs. Actual Values:\")\n",
    "print(final_forecast_df.to_string(index=False))\n",
    "\n",
    "# Display Validation and Test Metrics\n",
    "validation_metrics_df = pd.DataFrame(validation_metrics, columns=[\"Symbol\", \"Fold\", \"Validation MAE\", \"Validation MSE\", \"Validation RMSE\", \"Validation MAPE\"])\n",
    "test_metrics_df = pd.DataFrame(test_metrics, columns=[\"Symbol\", \"Test MAE\", \"Test MSE\", \"Test RMSE\", \"Test MAPE\"])\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(validation_metrics_df)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(test_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eef477-2c02-457b-b852-ef2218a67e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
