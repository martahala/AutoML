{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36a244-3927-4861-89c8-1e32ad8180f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # https://docs.python.org/3/library/os.html\n",
    "import pandas as pd # https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "import numpy as np # https://numpy.org/doc/2.2/\n",
    "import matplotlib.pyplot as plt # https://matplotlib.org/stable/index.html\n",
    "import optuna # https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/002_configurations.html\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error # https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "from keras.models import Sequential # https://keras.io/guides/sequential_model/\n",
    "from keras.layers import LSTM, Dropout, Dense # https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "from keras.optimizers import Adam # https://keras.io/api/optimizers/adam/\n",
    "from keras.callbacks import EarlyStopping # https://keras.io/api/callbacks/early_stopping/\n",
    "from sklearn.model_selection import TimeSeriesSplit # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "\n",
    "# Folder paths for training and test datasets\n",
    "train_folder = \" \" # Path to a train set\n",
    "test_folder = \" \" # Path to a test set\n",
    "\n",
    "# Function to load and concatenate all CSV files in a folder into a single DataFrame\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "def load_multiple_csv(folder_path):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    # Read each CSV and concatenate them into a single DataFrame\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, csv_file)) for csv_file in csv_files]\n",
    "    # Concatenate all DataFrames and reset index\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = load_multiple_csv(train_folder)\n",
    "test_df = load_multiple_csv(test_folder)\n",
    "\n",
    "# Ensure data was loaded properly\n",
    "if train_df is None or test_df is None:\n",
    "    raise ValueError(\"Error: Could not load training or testing data.\")\n",
    "\n",
    "# Convert Date column to DateTime format and set it as index\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "train_df[\"Date\"] = pd.to_datetime(train_df[\"Date\"])\n",
    "test_df[\"Date\"] = pd.to_datetime(test_df[\"Date\"])\n",
    "train_df.set_index(\"Date\", inplace=True) # Set Date column as index https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html\n",
    "test_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Encode the 'Symbol' column to numerical values\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "encoder = LabelEncoder()\n",
    "train_df[\"Symbol_Encoded\"] = encoder.fit_transform(train_df[\"Symbol\"])\n",
    "test_df[\"Symbol_Encoded\"] = encoder.transform(test_df[\"Symbol\"])\n",
    "\n",
    "# Save mappings for future reference or output\n",
    "symbol_mapping = dict(zip(train_df[\"Symbol_Encoded\"], train_df[\"Symbol\"]))\n",
    "name_mapping = dict(zip(train_df[\"Symbol_Encoded\"], train_df[\"Name\"]))\n",
    "\n",
    "# Remove original Symbol and Name columns\n",
    "train_df = train_df.drop(columns=[\"Symbol\", \"Name\"])\n",
    "test_df = test_df.drop(columns=[\"Symbol\", \"Name\"])\n",
    "\n",
    "# Initialize containers for forecasts and evaluation metrics\n",
    "all_forecasts = []\n",
    "test_metrics = []\n",
    "\n",
    "features = ['Close','High','Low','Open','Marketcap','Volume','trend','MA_7d','MA_14d', 'MA_30d']\n",
    "\n",
    "time_step = 30\n",
    "# Set up time series cross-validator\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Loop over each crypto asset (by encoded symbol)\n",
    "for symbol_encoded in train_df[\"Symbol_Encoded\"].unique(): # https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html\n",
    "    train_crypto_data = train_df[train_df[\"Symbol_Encoded\"] == symbol_encoded].copy() # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html\n",
    "    test_crypto_data = test_df[test_df[\"Symbol_Encoded\"] == symbol_encoded].copy()\n",
    "\n",
    "    train_crypto_data.sort_index(inplace=True) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html\n",
    "    test_crypto_data.sort_index(inplace=True)\n",
    "\n",
    "    print(f\"\\n Running LSTM Forecast for {symbol_mapping[symbol_encoded]} ({name_mapping[symbol_encoded]})\")\n",
    "\n",
    "    # Scale each feature individually using MinMaxScaler\n",
    "    # https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "    scaler_dict = {col: MinMaxScaler() for col in features}\n",
    "    scaled_train_data = np.zeros_like(train_crypto_data[features].values)\n",
    "    scaled_test_data = np.zeros_like(test_crypto_data[features].values)\n",
    "\n",
    "    for idx, col in enumerate(features):\n",
    "        scaled_train_data[:, idx] = scaler_dict[col].fit_transform(train_crypto_data[[col]]).flatten()\n",
    "        scaled_test_data[:, idx] = scaler_dict[col].transform(test_crypto_data[[col]]).flatten()\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(time_step, len(scaled_train_data)):\n",
    "        X.append(scaled_train_data[i - time_step:i])\n",
    "        y.append(scaled_train_data[i, features.index(\"Close\")])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Define LSTM model using Optuna\n",
    "    def objective(trial):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(trial.suggest_int(\"lstm1_units\", 32, 128), return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "        model.add(Dropout(trial.suggest_float(\"dropout1\", 0.2, 0.5)))\n",
    "        model.add(LSTM(trial.suggest_int(\"lstm2_units\", 16, 64)))\n",
    "        model.add(Dropout(trial.suggest_float(\"dropout2\", 0.2, 0.5)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer=Adam(learning_rate=trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)), loss='mean_squared_error')\n",
    "\n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0,\n",
    "                      validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        return model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(\"  -> Running Optuna...\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    print(f\"  -> Best Params: {study.best_params}\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(best_params[\"lstm1_units\"], return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dropout(best_params[\"dropout1\"]))\n",
    "    model.add(LSTM(best_params[\"lstm2_units\"]))\n",
    "    model.add(Dropout(best_params[\"dropout2\"]))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=best_params[\"lr\"]), loss='mean_squared_error')\n",
    "    model.fit(X, y, epochs=10, batch_size=16, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Predict first 7 days of the test set using rolling forecast\n",
    "    last_window = scaled_train_data[:7]\n",
    "    rolling_predictions = []\n",
    "\n",
    "    for i in range(7):\n",
    "        input_seq = last_window[:7].reshape(1, 7, len(features))\n",
    "        pred = model.predict(input_seq, verbose=0)[0][0]\n",
    "\n",
    "        # Build the next input row\n",
    "        next_row = scaled_test_data[i].copy()\n",
    "        next_row[features.index(\"Close\")] = pred\n",
    "\n",
    "        last_window = np.vstack([last_window[1:], next_row]) # https://numpy.org/devdocs/reference/generated/numpy.vstack.html\n",
    "        rolling_predictions.append(pred)\n",
    "\n",
    "    # Unscale predictions and actual values\n",
    "    temp_scaled = np.zeros((7, len(features))) # https://numpy.org/devdocs/reference/generated/numpy.zeros.html\n",
    "    for i in range(7):\n",
    "        temp_scaled[i, features.index(\"Close\")] = rolling_predictions[i]\n",
    "    forecast_unscaled = scaler_dict[\"Close\"].inverse_transform(temp_scaled[:, [features.index(\"Close\")]]).flatten()\n",
    "    actual_values = test_crypto_data[\"Close\"].values[:7]\n",
    "\n",
    "    # Calculate test metrics\n",
    "    test_mae = mean_absolute_error(actual_values, forecast_unscaled) # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html\n",
    "    test_mse = mean_squared_error(actual_values, forecast_unscaled)  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "    test_rmse = np.sqrt(test_mse) # https://numpy.org/doc/2.1/reference/generated/numpy.sqrt.html\n",
    "    test_mape = mean_absolute_percentage_error(actual_values, forecast_unscaled) * 100 # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html\n",
    "    test_metrics.append([symbol_mapping[symbol_encoded], test_mae, test_mse, test_rmse, test_mape])\n",
    "\n",
    "    # Plot predictions\n",
    "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "    # https://matplotlib.org/stable/tutorials/index.html\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(test_crypto_data.index[:7], actual_values, label=\"Actual\", marker='o')\n",
    "    plt.plot(test_crypto_data.index[:7], forecast_unscaled, label=\"Predicted\", marker='x')\n",
    "    plt.title(f\"{symbol_mapping[symbol_encoded]}: Forecast for First 7 Days\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Build final forecast table for this crypto\n",
    "    forecast_table = pd.DataFrame({\n",
    "        \"Date\": test_crypto_data.index[:7],\n",
    "        \"Symbol\": symbol_mapping[symbol_encoded],\n",
    "        \"Actual Value\": actual_values,\n",
    "        \"Predicted Value\": forecast_unscaled\n",
    "    })\n",
    "    print(forecast_table)\n",
    "    all_forecasts.append(forecast_table)\n",
    "\n",
    "# Print evaluation metrics\n",
    "final_forecast_df = pd.concat(all_forecasts, ignore_index=True)\n",
    "print(\"\\nFinal Forecasted vs. Actual Values:\")\n",
    "print(final_forecast_df.to_string(index=False)) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_string.html\n",
    "\n",
    "test_metrics_df = pd.DataFrame(test_metrics, columns=[\"Symbol\", \"Test MAE\", \"Test MSE\", \"Test RMSE\", \"Test MAPE (%) 7d LSTM Optuna\"])\n",
    "print(\"\\nTest Metrics (First 7 Days):\")\n",
    "print(test_metrics_df)\n",
    "# Save the predictions as csv files\n",
    "test_metrics_df.to_csv(\"LSTM_Optuna_7d_metrics.csv\", index=False) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "final_forecast_df.to_csv(\"LSTM_Optuna_7d_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
