{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bacfd75-eb47-4c10-8b7d-42695a0bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # https://docs.python.org/3/library/os.html\n",
    "import pandas as pd # https://pandas.pydata.org/docs/getting_started/install.html\n",
    "\n",
    "# Folder path where CSV files are located\n",
    "folder_path = '' # Your path to a 'Train' folder\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each CSV file and read it into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    # Build the full path to the CSV file\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path) # https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "    \n",
    "    # Append DataFrame to the list\n",
    "    dfs.append(df) # https://pandas.pydata.org/pandas-docs/version/1.4/reference/api/pandas.DataFrame.append.html\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "full_df = pd.concat(dfs, ignore_index=True) # https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "\n",
    "# Print the first few rows of the combined DataFrame\n",
    "print(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2f33e-3b37-42a1-b19d-36effff35c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Date'] = pd.to_datetime(full_df['Date']) # https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "full_df=full_df.sort_values('Date') # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "print(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04571fa6-40a8-4c6f-b799-9089dd3424a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "# Label Encoding Symbols\n",
    "encoder = LabelEncoder()\n",
    "full_df['Symbol_Encoded'] = encoder.fit_transform(full_df['Symbol'])\n",
    "# Store mapping for later\n",
    "symbol_mapping = dict(zip(full_df[\"Symbol_Encoded\"], full_df[\"Symbol\"]))\n",
    "name_mapping = dict(zip(full_df[\"Symbol_Encoded\"], full_df[\"Name\"]))\n",
    "df_encoded = full_df.drop(columns=['Symbol','Name'])\n",
    "print(\"Symbol Mapping:\", symbol_mapping)\n",
    "# Display the new DataFrame\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3edb6-7119-4622-b922-562b9c6a9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "import seaborn as sns # https://seaborn.pydata.org/tutorial/introduction.html\n",
    "import matplotlib.pyplot as plt # https://matplotlib.org/2.0.2/users/pyplot_tutorial.html\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_encoded.corr() # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
    "\n",
    "# Get correlations with the target column\n",
    "target_column = 'Close'  # Replace with your target column name\n",
    "correlation_with_target = correlation_matrix[target_column]\n",
    "\n",
    "# Display the correlation with target, sorted in descending order\n",
    "print(correlation_with_target.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdfa761-d3bd-4e8e-9fbf-72f40bc5559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded\n",
    "# Check for missing values in the entire dataset\n",
    "missing_values = df_encoded.isnull().sum() # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc5f96-993f-4d12-8fe5-809ea5c2194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "from tslearn.clustering import TimeSeriesKMeans # https://tslearn.readthedocs.io/en/stable/gen_modules/clustering/tslearn.clustering.TimeSeriesKMeans.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Aggregate the data for each cryptocurrency to get a single row for each\n",
    "# Group by cryptocurrency symbol and calculate mean for each feature\n",
    "crypto_features = df_encoded.groupby('Symbol_Encoded')[['High','Low','Open',\n",
    "                                                        'Marketcap',\n",
    "                                                    'Volume','trend','MA_7d','MA_14d', 'MA_30d' ]].mean()\n",
    "n_clusters=6\n",
    "\n",
    "# Step 3: Apply KMeans clustering\n",
    "kmeans = TimeSeriesKMeans(n_clusters, metric=\"dtw\",\n",
    "                         max_iter=10, random_state=42)\n",
    "crypto_features['KMeans_Cluster'] = kmeans.fit_predict(crypto_features)\n",
    "\n",
    "# Step 4: Create a mapping of Symbol_Encoded to the cluster assignment\n",
    "symbol_mapping = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster']))\n",
    "\n",
    "# Step 5: Merge the cluster labels back into the original DataFrame\n",
    "# Merge based on Symbol_Encoded to ensure each cryptocurrency gets its assigned cluster\n",
    "df_encoded['KMeans_Cluster'] = df_encoded['Symbol_Encoded'].map(symbol_mapping) # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html\n",
    "\n",
    "# Step 6: Group cryptocurrencies by cluster and display the results\n",
    "clustered_cryptos = {}\n",
    "\n",
    "# Create a dictionary of clusters and their corresponding cryptocurrencies\n",
    "for cluster in df_encoded['KMeans_Cluster'].unique(): # https://pandas.pydata.org/docs/reference/api/pandas.unique.html\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos[cluster] = cluster_names\n",
    "# Display the clusters\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster:\")\n",
    "for cluster, names in clustered_cryptos.items(): # https://python-reference.readthedocs.io/en/latest/docs/dict/items.html\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\") # https://python-reference.readthedocs.io/en/latest/docs/str/join.html\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "\n",
    "# Step 10: Calculate Silhouette Score\n",
    "silhouette_avg = silhouette_score(crypto_features, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Visualize silhouette scores for each data point\n",
    "silhouette_values = silhouette_samples(crypto_features, kmeans.labels_)\n",
    "# Plotting the silhouette scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "y_lower = 10  # Initial y position for the first cluster\n",
    "for i in range(n_clusters):\n",
    "    # Aggregate the silhouette scores for samples belonging to the current cluster\n",
    "    ith_cluster_silhouette_values = silhouette_values[ kmeans.labels_== i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    \n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i  # Update y position for the next cluster\n",
    "    plt.fill_betweenx(\n",
    "        range(y_lower, y_upper),\n",
    "        ith_cluster_silhouette_values,\n",
    "        alpha=0.7,\n",
    "        label=f'Cluster {i + 1}'\n",
    "    )\n",
    "    # Compute the new y_lower for the next cluster\n",
    "    y_lower = y_upper + 10  \n",
    "\n",
    "plt.axvline(x=silhouette_avg, color='red', linestyle='--')\n",
    "plt.title('Silhouette Scores for n = 6')\n",
    "plt.xlabel('Silhouette Coefficient')\n",
    "plt.ylabel('Cluster Label')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8d4b9-1510-45a0-bfc7-cf9e9f9013d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Aggregate the data for each cryptocurrency to get a single row for each\n",
    "# Group by cryptocurrency symbol and calculate mean for each feature\n",
    "crypto_features = df_encoded.groupby('Symbol_Encoded')[[['High','Low','Open',\n",
    "                                                        'Marketcap',\n",
    "                                                    'Volume','trend','MA_7d','MA_14d', 'MA_30d']].mean()]].mean()\n",
    "n_clusters = 2\n",
    "# Step 2: Standardize the data\n",
    "scaler = RobustScaler()\n",
    "crypto_scaled = scaler.fit_transform(crypto_features)\n",
    "# Step 3: Apply KMeans clustering\n",
    "kmeans = TimeSeriesKMeans(n_clusters, metric=\"dtw\",\n",
    "                         max_iter=10, random_state=42)\n",
    "crypto_features['KMeans_Cluster'] = kmeans.fit_predict(crypto_scaled)\n",
    "\n",
    "# Step 4: Create a mapping of Symbol_Encoded to the cluster assignment\n",
    "symbol_mapping = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster']))\n",
    "\n",
    "# Step 5: Merge the cluster labels back into the original DataFrame\n",
    "# Merge based on Symbol_Encoded to ensure each cryptocurrency gets its assigned cluster\n",
    "df_encoded['KMeans_Cluster'] = df_encoded['Symbol_Encoded'].map(symbol_mapping)\n",
    "\n",
    "# Step 6: Group cryptocurrencies by cluster and display the results\n",
    "clustered_cryptos = {}\n",
    "# Create a dictionary of clusters and their corresponding cryptocurrencies\n",
    "for cluster in df_encoded['KMeans_Cluster'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos[cluster] = cluster_names\n",
    "# Display the clusters\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster:\")\n",
    "for cluster, names in clustered_cryptos.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "\n",
    "# Step 10: Calculate Silhouette Score\n",
    "silhouette_avg = silhouette_score(crypto_scaled, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Visualize silhouette scores for each data point\n",
    "silhouette_values = silhouette_samples(crypto_scaled, kmeans.labels_)\n",
    "# Plotting the silhouette scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "y_lower = 10  # Initial y position for the first cluster\n",
    "for i in range(n_clusters):\n",
    "    # Aggregate the silhouette scores for samples belonging to the current cluster\n",
    "    ith_cluster_silhouette_values = silhouette_values[ kmeans.labels_== i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    \n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i  # Update y position for the next cluster\n",
    "    plt.fill_betweenx(\n",
    "        range(y_lower, y_upper),\n",
    "        ith_cluster_silhouette_values,\n",
    "        alpha=0.7,\n",
    "        label=f'Cluster {i + 1}'\n",
    "    )\n",
    "    # Compute the new y_lower for the next cluster\n",
    "    y_lower = y_upper + 10  \n",
    "\n",
    "plt.axvline(x=silhouette_avg, color='red', linestyle='--')\n",
    "plt.title('Silhouette Scores for n = 2')\n",
    "plt.xlabel('Silhouette Coefficient')\n",
    "plt.ylabel('Cluster Label')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b2b95-62aa-46f1-9b36-adbb43f38521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "from sklearn.decomposition import PCA # https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Aggregate the data for each cryptocurrency\n",
    "crypto_features = df_encoded.groupby('Symbol_Encoded')[['High','Low','Open',\n",
    "                                                        'Marketcap',\n",
    "                                                    'Volume','trend','MA_7d','MA_14d', 'MA_30d']].mean()\n",
    "n_clusters = 2\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "crypto_scaled = scaler.fit_transform(crypto_features)\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "crypto_pca = pca.fit_transform(crypto_scaled)\n",
    "\n",
    "# Step 4: Apply KMeans clustering on the original features\n",
    "kmeans_original = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_original.fit(crypto_scaled)\n",
    "crypto_features['KMeans_Cluster_Original'] = kmeans_original.labels_\n",
    "\n",
    "# Step 5: Apply KMeans clustering on PCA-reduced features\n",
    "kmeans_pca = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_pca.fit(crypto_pca)\n",
    "crypto_features['KMeans_Cluster_PCA'] = kmeans_pca.labels_\n",
    "\n",
    "# Step 6: Compare the clustering results\n",
    "symbol_mapping_original = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_Original']))\n",
    "symbol_mapping_pca = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_PCA']))\n",
    "\n",
    "df_encoded['KMeans_Cluster_Original'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_original)\n",
    "df_encoded['KMeans_Cluster_PCA'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_pca)\n",
    "\n",
    "# Step 7: Compute and compare silhouette scores\n",
    "silhouette_original = silhouette_score(crypto_scaled, kmeans_original.labels_)\n",
    "silhouette_pca = silhouette_score(crypto_pca, kmeans_pca.labels_)\n",
    "\n",
    "print(f\"Silhouette Score (Original Features): {silhouette_original}\")\n",
    "print(f\"Silhouette Score (PCA-Reduced Features): {silhouette_pca}\")\n",
    "\n",
    "# Step 8: Visualize PCA components\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=crypto_pca[:, 0], y=crypto_pca[:, 1], hue=crypto_features['KMeans_Cluster_PCA'], palette='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Scatter Plot of Cryptocurrencies')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Group cryptocurrencies by cluster for both methods\n",
    "clustered_cryptos_original = {}\n",
    "clustered_cryptos_pca = {}\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_Original'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_Original'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_original[cluster] = cluster_names\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_PCA'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_PCA'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_pca[cluster] = cluster_names\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Clusters (Original Features):\")\n",
    "for cluster, names in clustered_cryptos_original.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (PCA Features):\")\n",
    "for cluster, names in clustered_cryptos_pca.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab925fd2-d1bc-42eb-b305-37f126bed1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator # https://kneed.readthedocs.io/en/stable/parameters.html\n",
    "\n",
    "# Step 1: Aggregate the data for each cryptocurrency\n",
    "crypto_features = df_encoded.groupby('Symbol_Encoded')[['High','Low','Open',\n",
    "                                                        'Marketcap',\n",
    "                                                    'Volume','trend','MA_7d','MA_14d', 'MA_30d']].mean()\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "crypto_scaled = scaler.fit_transform(crypto_features)\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction (2 and 3 components)\n",
    "pca2 = PCA(n_components=2)\n",
    "crypto_pca2 = pca2.fit_transform(crypto_scaled)\n",
    "\n",
    "pca3 = PCA(n_components=3)\n",
    "crypto_pca3 = pca3.fit_transform(crypto_scaled)\n",
    "\n",
    "# Step 4: Determine the optimal number of clusters using Silhouette Score\n",
    "silhouette_scores_original = []\n",
    "silhouette_scores_pca2 = []\n",
    "silhouette_scores_pca3 = []\n",
    "k_values = range(2, 11)  # Silhouette Score requires at least 2 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans_original = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_original = kmeans_original.fit_predict(crypto_scaled)\n",
    "    silhouette_scores_original.append(silhouette_score(crypto_scaled, labels_original))\n",
    "    \n",
    "    kmeans_pca2 = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_pca2 = kmeans_pca2.fit_predict(crypto_pca2)\n",
    "    silhouette_scores_pca2.append(silhouette_score(crypto_pca2, labels_pca2))\n",
    "    \n",
    "    kmeans_pca3 = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_pca3 = kmeans_pca3.fit_predict(crypto_pca3)\n",
    "    silhouette_scores_pca3.append(silhouette_score(crypto_pca3, labels_pca3))\n",
    "\n",
    "# Find the optimal number of clusters using kneed\n",
    "knee_original = KneeLocator(k_values, silhouette_scores_original, curve=\"convex\", direction=\"decreasing\")\n",
    "knee_pca2 = KneeLocator(k_values, silhouette_scores_pca2, curve=\"convex\", direction=\"decreasing\")\n",
    "knee_pca3 = KneeLocator(k_values, silhouette_scores_pca3, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "optimal_clusters_original = knee_original.knee\n",
    "optimal_clusters_pca2 = knee_pca2.knee\n",
    "optimal_clusters_pca3 = knee_pca3.knee\n",
    "\n",
    "print(f\"Optimal number of clusters (Original Features): {optimal_clusters_original}\")\n",
    "print(f\"Optimal number of clusters (PCA2 Features): {optimal_clusters_pca2}\")\n",
    "print(f\"Optimal number of clusters (PCA3 Features): {optimal_clusters_pca3}\")\n",
    "\n",
    "# Step 5: Apply KMeans clustering on the original and PCA features with optimal clusters\n",
    "kmeans_original = TimeSeriesKMeans(n_clusters=optimal_clusters_original, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_original.fit(crypto_scaled)\n",
    "crypto_features['KMeans_Cluster_Original'] = kmeans_original.labels_\n",
    "\n",
    "kmeans_pca2 = TimeSeriesKMeans(n_clusters=optimal_clusters_pca2, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_pca2.fit(crypto_pca2)\n",
    "crypto_features['KMeans_Cluster_PCA2'] = kmeans_pca2.labels_\n",
    "\n",
    "kmeans_pca3 = TimeSeriesKMeans(n_clusters=optimal_clusters_pca3, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_pca3.fit(crypto_pca3)\n",
    "crypto_features['KMeans_Cluster_PCA3'] = kmeans_pca3.labels_\n",
    "\n",
    "# Step 6: Compare the clustering results\n",
    "symbol_mapping_original = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_Original']))\n",
    "symbol_mapping_pca2 = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_PCA2']))\n",
    "symbol_mapping_pca3 = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_PCA3']))\n",
    "\n",
    "df_encoded['KMeans_Cluster_Original'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_original)\n",
    "df_encoded['KMeans_Cluster_PCA2'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_pca2)\n",
    "df_encoded['KMeans_Cluster_PCA3'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_pca3)\n",
    "\n",
    "# Step 7: Group cryptocurrencies by cluster\n",
    "clustered_cryptos_original = {}\n",
    "clustered_cryptos_pca2 = {}\n",
    "clustered_cryptos_pca3 = {}\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_Original'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_Original'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_original[cluster] = cluster_names\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_PCA2'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_PCA2'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_pca2[cluster] = cluster_names\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_PCA3'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_PCA3'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_pca3[cluster] = cluster_names\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (Original Features):\")\n",
    "for cluster, names in clustered_cryptos_original.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (PCA2 Features):\")\n",
    "for cluster, names in clustered_cryptos_pca2.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (PCA3 Features):\")\n",
    "for cluster, names in clustered_cryptos_pca3.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "# Step 8: Compare the Silhouette Scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, silhouette_scores_original, marker='o', linestyle='-', color='b', label='Original Features')\n",
    "plt.plot(k_values, silhouette_scores_pca2, marker='s', linestyle='-', color='g', label='PCA2 Features')\n",
    "plt.plot(k_values, silhouette_scores_pca3, marker='^', linestyle='-', color='r', label='PCA3 Features')\n",
    "plt.axvline(x=optimal_clusters_original, color='b', linestyle='--', label=f'Optimal k (Original) = {optimal_clusters_original}')\n",
    "plt.axvline(x=optimal_clusters_pca2, color='g', linestyle='--', label=f'Optimal k (PCA2) = {optimal_clusters_pca2}')\n",
    "plt.axvline(x=optimal_clusters_pca3, color='r', linestyle='--', label=f'Optimal k (PCA3) = {optimal_clusters_pca3}')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score Comparison: Original vs PCA2 vs PCA3\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99899a5-5554-4427-a530-9cc586884e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 5\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Step 1: Aggregate the data for each cryptocurrency\n",
    "crypto_features = df_encoded.groupby('Symbol_Encoded')[['High','Low','Open',\n",
    "                                                        'Marketcap',\n",
    "                                                    'Volume','trend','MA_7d','MA_14d', 'MA_30d']].mean()\n",
    "\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction (2 and 3 components)\n",
    "pca2 = PCA(n_components=2)\n",
    "crypto_pca2 = pca2.fit_transform(crypto_features)\n",
    "\n",
    "pca3 = PCA(n_components=3)\n",
    "crypto_pca3 = pca3.fit_transform(crypto_features)\n",
    "\n",
    "# Step 4: Determine the optimal number of clusters using Silhouette Score\n",
    "silhouette_scores_original = []\n",
    "silhouette_scores_pca2 = []\n",
    "silhouette_scores_pca3 = []\n",
    "k_values = range(2, 11)  # Silhouette Score requires at least 2 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans_original = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_original = kmeans_original.fit_predict(crypto_features)\n",
    "    silhouette_scores_original.append(silhouette_score(crypto_features, labels_original))\n",
    "    \n",
    "    kmeans_pca2 = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_pca2 = kmeans_pca2.fit_predict(crypto_pca2)\n",
    "    silhouette_scores_pca2.append(silhouette_score(crypto_pca2, labels_pca2))\n",
    "    \n",
    "    kmeans_pca3 = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "    labels_pca3 = kmeans_pca3.fit_predict(crypto_pca3)\n",
    "    silhouette_scores_pca3.append(silhouette_score(crypto_pca3, labels_pca3))\n",
    "# Find the optimal number of clusters using kneed\n",
    "knee_original = KneeLocator(k_values, silhouette_scores_original, curve=\"convex\", direction=\"decreasing\")\n",
    "knee_pca2 = KneeLocator(k_values, silhouette_scores_pca2, curve=\"convex\", direction=\"decreasing\")\n",
    "knee_pca3 = KneeLocator(k_values, silhouette_scores_pca3, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "optimal_clusters_original = knee_original.knee\n",
    "optimal_clusters_pca2 = knee_pca2.knee\n",
    "optimal_clusters_pca3 = knee_pca3.knee\n",
    "\n",
    "print(f\"Optimal number of clusters (Original Features): {optimal_clusters_original}\")\n",
    "print(f\"Optimal number of clusters (PCA2 Features): {optimal_clusters_pca2}\")\n",
    "print(f\"Optimal number of clusters (PCA3 Features): {optimal_clusters_pca3}\")\n",
    "\n",
    "# Step 5: Apply KMeans clustering on the original and PCA features with optimal clusters\n",
    "kmeans_original = TimeSeriesKMeans(n_clusters=optimal_clusters_original, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_original.fit(crypto_features)\n",
    "crypto_features['KMeans_Cluster_Original'] = kmeans_original.labels_\n",
    "kmeans_pca2 = TimeSeriesKMeans(n_clusters=optimal_clusters_pca2, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_pca2.fit(crypto_pca2)\n",
    "crypto_features['KMeans_Cluster_PCA2'] = kmeans_pca2.labels_\n",
    "\n",
    "kmeans_pca3 = TimeSeriesKMeans(n_clusters=optimal_clusters_pca3, metric=\"dtw\", max_iter=10, random_state=42)\n",
    "kmeans_pca3.fit(crypto_pca3)\n",
    "crypto_features['KMeans_Cluster_PCA3'] = kmeans_pca3.labels_\n",
    "\n",
    "# Step 6: Compare the clustering results\n",
    "symbol_mapping_original = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_Original']))\n",
    "symbol_mapping_pca2 = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_PCA2']))\n",
    "symbol_mapping_pca3 = dict(zip(crypto_features.index, crypto_features['KMeans_Cluster_PCA3']))\n",
    "\n",
    "df_encoded['KMeans_Cluster_Original'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_original)\n",
    "df_encoded['KMeans_Cluster_PCA2'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_pca2)\n",
    "df_encoded['KMeans_Cluster_PCA3'] = df_encoded['Symbol_Encoded'].map(symbol_mapping_pca3)\n",
    "\n",
    "# Step 7: Group cryptocurrencies by cluster\n",
    "clustered_cryptos_original = {}\n",
    "clustered_cryptos_pca2 = {}\n",
    "clustered_cryptos_pca3 = {}\n",
    "for cluster in df_encoded['KMeans_Cluster_Original'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_Original'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_original[cluster] = cluster_names\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_PCA2'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_PCA2'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_pca2[cluster] = cluster_names\n",
    "\n",
    "for cluster in df_encoded['KMeans_Cluster_PCA3'].unique():\n",
    "    cluster_symbols = df_encoded[df_encoded['KMeans_Cluster_PCA3'] == cluster]['Symbol_Encoded'].unique()\n",
    "    cluster_names = [name_mapping[symbol] for symbol in cluster_symbols]\n",
    "    clustered_cryptos_pca3[cluster] = cluster_names\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (Original Features):\")\n",
    "for cluster, names in clustered_cryptos_original.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (PCA2 Features):\")\n",
    "for cluster, names in clustered_cryptos_pca2.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "print(\"\\nCryptocurrencies Grouped by Cluster (PCA3 Features):\")\n",
    "for cluster, names in clustered_cryptos_pca3.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(names)}\")\n",
    "\n",
    "# Step 8: Compare the Silhouette Scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, silhouette_scores_original, marker='o', linestyle='-', color='b', label='Original Features')\n",
    "plt.plot(k_values, silhouette_scores_pca2, marker='s', linestyle='-', color='g', label='PCA2 Features')\n",
    "plt.plot(k_values, silhouette_scores_pca3, marker='^', linestyle='-', color='r', label='PCA3 Features')\n",
    "plt.axvline(x=optimal_clusters_original, color='b', linestyle='--', label=f'Optimal k (Original) = {optimal_clusters_original}')\n",
    "plt.axvline(x=optimal_clusters_pca2, color='g', linestyle='--', label=f'Optimal k (PCA2) = {optimal_clusters_pca2}')\n",
    "plt.axvline(x=optimal_clusters_pca3, color='r', linestyle='--', label=f'Optimal k (PCA3) = {optimal_clusters_pca3}')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score Comparison: Original vs PCA2 vs PCA3\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Silhouette Score (Original Features): {silhouette_scores_original}\")\n",
    "print(f\"Final Silhouette Score (PCA2-Reduced Features): {silhouette_scores_pca2}\")\n",
    "print(f\"Final Silhouette Score (PCA3-Reduced Features): {silhouette_scores_pca3}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
